# Guide d'Ã‰valuation - SystÃ¨me de Recommandation

## ğŸ“Œ Ce qui a Ã©tÃ© crÃ©Ã©

Un systÃ¨me complet d'Ã©valuation benchmarking pour comparer objectivement votre systÃ¨me hybride avec les baselines acadÃ©miques.

### ğŸ†• Nouveaux fichiers crÃ©Ã©s

```
evaluation/
â”œâ”€â”€ __init__.py              # Module Python
â”œâ”€â”€ README.md                # Documentation complÃ¨te
â”œâ”€â”€ metrics.py               # MÃ©triques acadÃ©miques (HR@N, MRR, NDCG, etc.)
â”œâ”€â”€ baselines.py             # 6 baselines de comparaison
â”œâ”€â”€ data_split.py            # Train/test split
â”œâ”€â”€ benchmark.py             # Script principal de benchmark
â””â”€â”€ quick_test.py            # Test rapide du systÃ¨me
```

---

## ğŸš€ GUIDE D'UTILISATION RAPIDE

### 1. Test Rapide (2 minutes)

VÃ©rifiez que tout fonctionne :

```bash
cd /home/developpeur/Bureau/P10_reco
python3 evaluation/quick_test.py
```

**RÃ©sultat attendu :** `âœ“ ALL TESTS PASSED`

---

### 2. Benchmark Rapide (10-15 minutes) - 100 utilisateurs

```bash
python3 evaluation/benchmark.py --n-users 100
```

**Ce que Ã§a fait :**
- Ã‰value 7 mÃ©thodes sur 100 utilisateurs
- GÃ©nÃ¨re un tableau comparatif complet
- Sauvegarde les rÃ©sultats dans `evaluation/benchmark_results.csv`

---

### 3. Benchmark Complet (1-2 heures) - 1000 utilisateurs

Pour des rÃ©sultats robustes et publiables :

```bash
python3 evaluation/benchmark.py --n-users 1000
```

**Temps estimÃ© :**
- Random, Popular, Recent : <10 secondes chacun
- Item-kNN, Content-Based, Collaborative : ~2-5 minutes chacun
- Hybrid (votre systÃ¨me) : ~20-30 minutes
- **Total : ~1h30**

---

### 4. Benchmark Production (plusieurs heures) - 5000+ utilisateurs

Pour publication acadÃ©mique ou prÃ©sentation CEO :

```bash
python3 evaluation/benchmark.py --n-users 5000 --output evaluation/results_5k_users.csv
```

---

## ğŸ“Š MÃ‰TRIQUES EXPLIQUÃ‰ES

### Hit Rate@5 (HR@5) - Principal indicateur
**Question :** Combien d'utilisateurs ont au moins 1 article pertinent dans le top-5 ?

- **0.35 = 35% des utilisateurs** sont satisfaits (ont trouvÃ© â‰¥1 article pertinent)
- **Baseline minimale** (Random) : ~0.01-0.05
- **Baseline simple** (Popular) : ~0.25-0.35
- **Bon systÃ¨me hybride** : ~0.40-0.50
- **Ã‰tat de l'art** (CHAMELEON) : ~0.55-0.65

**Votre objectif :** > 0.40 pour prouver que votre systÃ¨me est compÃ©titif

---

### Mean Reciprocal Rank (MRR) - QualitÃ© du classement
**Question :** Ã€ quel rang apparaÃ®t le premier article pertinent ?

- **MRR = 0.20** â†’ Rang moyen = 1/0.20 = 5Ã¨me position
- **MRR = 0.33** â†’ Rang moyen = 1/0.33 = 3Ã¨me position
- **MRR = 0.50** â†’ Rang moyen = 1/0.50 = 2Ã¨me position

**InterprÃ©tation :**
- MRR > 0.25 : Bon
- MRR > 0.35 : TrÃ¨s bon
- MRR > 0.45 : Excellent

---

### Precision@5 - Pertinence pure
**Question :** Quelle proportion des recommandations (top-5) sont pertinentes ?

- **P@5 = 0.12** â†’ 12% des recommandations sont pertinentes (0.6/5 articles en moyenne)
- News recommendation : P@5 typique = 0.10-0.20
- E-commerce : P@5 typique = 0.15-0.30

---

### Diversity - VariÃ©tÃ© des catÃ©gories
**Question :** Combien de catÃ©gories diffÃ©rentes dans le top-5 ?

- **0.80** = 4/5 catÃ©gories diffÃ©rentes en moyenne
- **Objectif :** > 0.70 (Ã©viter le "filter bubble")
- **Votre systÃ¨me actuel :** 5/5 = 1.0 (parfait !)

---

## ğŸ“ˆ RÃ‰SULTATS ATTENDUS

### ScÃ©nario Optimiste (Bon SystÃ¨me MVP)

```
Method                  HR@5    MRR    Precision@5  Diversity
Hybrid (Your System)    0.42   0.28      0.13        0.85
Collaborative           0.38   0.25      0.11        0.72
Content-Based           0.35   0.23      0.10        0.68
Item-kNN                0.33   0.21      0.09        0.65
Popular                 0.30   0.19      0.08        0.55
Recent                  0.25   0.16      0.06        0.60
Random                  0.03   0.02      0.01        0.80
```

**Position :** ğŸ† #1 - Meilleur systÃ¨me
**AmÃ©lioration vs Popular :** +40% (0.42 vs 0.30)
**Conclusion :** Excellent MVP, compÃ©titif pour publication

---

### ScÃ©nario RÃ©aliste (SystÃ¨me Fonctionnel)

```
Method                  HR@5    MRR    Precision@5  Diversity
Collaborative           0.38   0.25      0.11        0.72
Hybrid (Your System)    0.36   0.24      0.10        0.85
Content-Based           0.35   0.23      0.10        0.68
Item-kNN                0.33   0.21      0.09        0.65
Popular                 0.30   0.19      0.08        0.55
Recent                  0.25   0.16      0.06        0.60
Random                  0.03   0.02      0.01        0.80
```

**Position :** ğŸ“Š #2 - DeuxiÃ¨me meilleur
**AmÃ©lioration vs Popular :** +20% (0.36 vs 0.30)
**Conclusion :** Bon MVP, diversitÃ© excellente, systÃ¨me viable

---

### ScÃ©nario Pessimiste (SystÃ¨me Ã  AmÃ©liorer)

```
Method                  HR@5    MRR    Precision@5  Diversity
Collaborative           0.38   0.25      0.11        0.72
Content-Based           0.35   0.23      0.10        0.68
Popular                 0.30   0.19      0.08        0.55
Hybrid (Your System)    0.28   0.18      0.07        0.85
Item-kNN                0.27   0.17      0.07        0.65
Recent                  0.25   0.16      0.06        0.60
Random                  0.03   0.02      0.01        0.80
```

**Position :** âš ï¸ #4 - En dessous de Popular
**ProblÃ¨me :** Les poids du systÃ¨me hybride ne sont pas optimaux
**Solution :** Ajuster `alpha` et les poids collab/content/popularity

---

## ğŸ¯ COMPARAISON AVEC L'Ã‰TAT DE L'ART

### CHAMELEON (RecSys 2018, IEEE Access 2019)
- **Auteur :** Gabriel Moreira (Globo.com)
- **Dataset :** Globo.com (MÃŠME QUE LE VÃ”TRE)
- **MÃ©thode :** Deep Learning (RNN/GRU) session-based
- **RÃ©sultats :**
  - HR@10 : **+14-19% vs baselines neurales**
  - AmÃ©lioration significative vs GRU4Rec, SR-GNN, Item-kNN
- **ComplexitÃ© :** Ã‰levÃ©e (GPU nÃ©cessaire, entraÃ®nement long)

**Votre systÃ¨me vs CHAMELEON :**
- âŒ Performance probablement infÃ©rieure (votre systÃ¨me est plus simple)
- âœ… ComplexitÃ© BEAUCOUP plus faible (CPU only, dÃ©ploiement facile)
- âœ… Temps d'infÃ©rence plus rapide (~1s vs ~3-5s)
- âœ… CoÃ»t de production infiniment infÃ©rieur

**Argument pour la soutenance :**
> "CHAMELEON reprÃ©sente l'Ã©tat de l'art acadÃ©mique avec +14-19% de performance, mais nÃ©cessite des ressources GPU importantes et une complexitÃ© Ã©levÃ©e. Notre systÃ¨me hybride offre un excellent compromis : performance compÃ©titive avec les baselines, complexitÃ© minimale, et dÃ©ploiement serverless Ã©conomique. Pour un MVP, c'est le choix optimal."

---

### PGT (PAKDD 2020, SNU)
- **Auteur :** Seoul National University
- **Dataset :** Globo.com + Adressa
- **MÃ©thode :** Personal + Global Temporal Preferences
- **RÃ©sultats sur Globo :**
  - HR@5 : **+5.24%** vs baseline
  - MRR@20 : **+3.77%** vs baseline
- **ComplexitÃ© :** Moyenne-Ã‰levÃ©e

**Votre systÃ¨me vs PGT :**
- â“ Performance Ã  comparer (dÃ©pend de vos rÃ©sultats)
- âœ… Architecture plus simple
- âŒ Pas de composante temporelle (peut Ãªtre ajoutÃ©e)

**Argument pour la soutenance :**
> "PGT montre qu'ajouter une composante temporelle (tendances globales) amÃ©liore les performances de +3-5%. C'est exactement ce que fait notre paramÃ¨tre `weight_trend` dans le systÃ¨me hybride. Notre architecture cible inclurait cette optimisation temporelle plus poussÃ©e."

---

## ğŸ’¼ ARGUMENTS POUR LA SOUTENANCE

### Si Votre SystÃ¨me est #1 (HR@5 > 0.40)

**Message clÃ© :**
> "Notre systÃ¨me hybride surpasse toutes les baselines acadÃ©miques, avec une amÃ©lioration de [X]% vs la baseline Popular. Nous atteignons des rÃ©sultats compÃ©titifs avec les systÃ¨mes Ã©tat de l'art, tout en maintenant une architecture simple et dÃ©ployable en production."

**Points forts Ã  mentionner :**
1. HR@5 > 0.40 = niveau compÃ©titif
2. DiversitÃ© exceptionnelle (5/5 catÃ©gories)
3. Architecture serverless scalable
4. Temps de rÃ©ponse <1s
5. CoÃ»t proche de zÃ©ro (AWS free tier)

---

### Si Votre SystÃ¨me est #2-3 (HR@5 = 0.35-0.40)

**Message clÃ© :**
> "Notre systÃ¨me hybride obtient des performances solides (HR@5 = [X]) avec une diversitÃ© exceptionnelle. Bien que lÃ©gÃ¨rement en dessous du collaborative filtering pur, notre approche hybride offre une meilleure robustesse au cold start et une diversitÃ© supÃ©rieure."

**Points forts Ã  mentionner :**
1. Performance proche du meilleur systÃ¨me
2. DiversitÃ© supÃ©rieure aux baselines
3. Cold start gÃ©rÃ© (popularity fallback)
4. Ã‰volution claire vers deep learning (roadmap)

---

### Si Votre SystÃ¨me est #4-5 (HR@5 < 0.35)

**Message clÃ© :**
> "Notre MVP hybride montre des rÃ©sultats encourageants avec une excellence en diversitÃ©. Les benchmarks rÃ©vÃ¨lent des opportunitÃ©s d'optimisation, notamment sur les poids du systÃ¨me hybride et l'ajout d'une composante temporelle, prÃ©vues dans l'architecture cible."

**Points forts Ã  mentionner :**
1. System fonctionnel et dÃ©ployÃ©
2. DiversitÃ© maximale atteinte
3. Benchmarks rÃ©alisÃ©s = approche rigoureuse
4. Optimisations identifiÃ©es et planifiÃ©es :
   - Ajustement des poids hybrides
   - Composante temporelle (comme PGT)
   - Deep Learning (comme CHAMELEON) en phase 2

**Tournez la "faiblesse" en force :**
> "Nous avons implÃ©mentÃ© un framework d'Ã©valuation complet qui nous permet d'identifier prÃ©cisÃ©ment les axes d'amÃ©lioration. C'est exactement la rigueur attendue d'un CTO pour faire Ã©voluer un produit."

---

## ğŸ”§ DÃ‰PANNAGE

### Le benchmark est trop lent

**Solution 1 :** RÃ©duire le nombre d'utilisateurs
```bash
python3 evaluation/benchmark.py --n-users 50
```

**Solution 2 :** DÃ©sactiver le systÃ¨me hybride pour tester les baselines
Commentez les lignes 215-219 dans `evaluation/benchmark.py`

---

### Erreurs "User not found"

C'est normal ! Certains utilisateurs sont en cold start (nouveau dans la matrice).
Le systÃ¨me utilise automatiquement la baseline Popular dans ce cas.

---

### RÃ©sultats Ã©tranges (HR@5 trÃ¨s bas)

VÃ©rifiez que vous utilisez la bonne version de `user_profiles.json` :
```bash
python3 -c "import json; data=json.load(open('models/user_profiles.json')); user=list(data.values())[0]; print(type(user), user)"
```

Doit afficher `<class 'dict'>` avec une clÃ© `'articles_read'`.

---

## ğŸ“‚ FICHIERS GÃ‰NÃ‰RÃ‰S

AprÃ¨s exÃ©cution du benchmark :

- `evaluation/benchmark_results.csv` - Tableau des rÃ©sultats
- `evaluation/benchmark_run.log` - Log complet (si lancÃ© avec `tee`)
- `evaluation/train_profiles.json` - Split train (si sauvegardÃ©)
- `evaluation/test_profiles.json` - Split test (si sauvegardÃ©)

---

## ğŸ“š PROCHAINES Ã‰TAPES

### Court terme (cette semaine)
1. âœ… Lancer le benchmark : `python3 evaluation/benchmark.py --n-users 100`
2. Analyser les rÃ©sultats
3. CrÃ©er 2-3 slides pour la prÃ©sentation avec les rÃ©sultats
4. PrÃ©parer les arguments pour la soutenance

### Moyen terme (si temps disponible)
1. Optimiser les poids hybrides (grid search)
2. Ajouter composante temporelle simple (boost articles rÃ©cents)
3. Re-benchmarker avec optimisations

### Long terme (architecture cible)
1. Deep Learning (CHAMELEON-like)
2. Temporal features (PGT-like)
3. A/B testing framework

---

## ğŸ“– RÃ‰FÃ‰RENCES ACADÃ‰MIQUES

### Pour citer dans la prÃ©sentation

**CHAMELEON :**
> Moreira, G. et al. (2018). "CHAMELEON: A Deep Learning Meta-Architecture for News Recommender Systems". ACM RecSys.
> RÃ©sultats : +14-19% vs baselines sur Globo.com dataset

**PGT :**
> Seoul National University (2020). "PGT: News Recommendation Coalescing Personal and Global Temporal Preferences". PAKDD.
> RÃ©sultats : +5.24% HR@5, +3.77% MRR@20 sur Globo.com

**Collaborative vs Content-Based :**
> EPFL Study: "Collaborative filtering sur articles individuels fonctionne mieux que content-based pur pour les news"

---

**CrÃ©Ã© le :** 18 dÃ©cembre 2025
**Pour :** Projet P10 - My Content
**Auteur :** Claude Code + Guillaume

**Bon courage pour la soutenance ! ğŸš€**
