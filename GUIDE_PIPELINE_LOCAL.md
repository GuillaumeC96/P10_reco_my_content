# Guide d'ex√©cution du Pipeline Local

## Pourquoi en local plut√¥t que Kaggle ?

‚úÖ **Avantages du pipeline local:**
1. **Contr√¥le total** - Pas de limite de temps (6h sur Kaggle)
2. **Debugging facile** - Acc√®s direct aux logs et fichiers
3. **Pr√©sentation** - D√©mo en direct possible
4. **Livrables propres** - Fichiers organis√©s et document√©s
5. **Reproductibilit√©** - Script automatis√© et versionn√©

## √âtapes du Pipeline

Le script `run_pipeline_complet.sh` ex√©cute automatiquement:

### 1. V√©rification des pr√©requis
- Python 3.x
- D√©pendances (pandas, numpy, scipy, sklearn)
- Dataset Globo.com

### 2. Exploration des donn√©es (optionnel)
- Statistiques descriptives
- Analyse de la distribution
- D√©tection des anomalies

### 3. Preprocessing
- Chargement de 385 fichiers de clics (streaming)
- Agr√©gation des interactions
- Cr√©ation matrice sparse user-item (CSR)
- G√©n√©ration profils utilisateurs
- Filtrage r√®gle 30s

**Sortie:** `user_item_matrix.npz`, `user_profiles.json`, `mappings.pkl`

### 4. Enrichissement
- Calcul des 9 signaux de qualit√©:
  1. Temps de lecture
  2. Nombre de clicks
  3. Qualit√© de session
  4. Type de device
  5. Syst√®me d'exploitation
  6. Pays
  7. R√©gion
  8. Referrer
  9. Environnement (app/web)

**Sortie:** `interaction_stats_enriched.csv` (426 MB)

### 5. Matrice pond√©r√©e
- Remplacement des counts par les weights
- Cr√©ation matrice sparse pond√©r√©e

**Sortie:** `user_item_matrix_weighted.npz` (9.2 MB)

### 6. Mod√®les Lite
- √âchantillonnage 10,000 utilisateurs
- R√©duction de 750 MB ‚Üí 86 MB
- Pour d√©ploiement cloud (Azure Functions)

**Sortie:** R√©pertoire `models_lite/`

### 7. Validation
- Test de chargement des mod√®les
- V√©rification de l'int√©grit√©
- Statistiques finales

## Utilisation

### Lancement du pipeline complet

```bash
cd /home/ser/Bureau/P10_reco_new
./run_pipeline_complet.sh
```

### Options disponibles

Le script est **interactif** pour certaines √©tapes:
- Si les fichiers existent d√©j√†, il demande confirmation avant de les r√©g√©n√©rer
- Vous pouvez arr√™ter √† tout moment avec `Ctrl+C`

### Temps d'ex√©cution estim√©

| √âtape | Dur√©e | Mat√©riel |
|-------|-------|----------|
| Exploration | 30s | CPU |
| Preprocessing | 15s | CPU + RAM (8 GB) |
| Enrichissement | **2-5 min** | CPU intensive |
| Matrice pond√©r√©e | 30s | CPU + RAM |
| Mod√®les Lite | 10s | CPU |
| **Total** | **5-10 min** | Variable |

### Ressources n√©cessaires

- **RAM:** 8 GB minimum (16 GB recommand√©)
- **Stockage:** 2 GB libre
- **CPU:** Multi-core recommand√© (parall√©lisation)

## Outputs g√©n√©r√©s

### Fichiers mod√®les

```
/home/ser/Bureau/P10_reco/models/
‚îú‚îÄ‚îÄ user_item_matrix.npz              # 4.4 MB
‚îú‚îÄ‚îÄ user_item_matrix_weighted.npz     # 9.2 MB
‚îú‚îÄ‚îÄ mappings.pkl                      # 3.2 MB
‚îú‚îÄ‚îÄ article_popularity.pkl            # 1.5 MB
‚îú‚îÄ‚îÄ user_profiles.json                # 64 MB
‚îú‚îÄ‚îÄ user_profiles_enriched.pkl        # Plus compact
‚îú‚îÄ‚îÄ embeddings_filtered.pkl           # 38 MB
‚îú‚îÄ‚îÄ articles_metadata.csv             # 11 MB
‚îú‚îÄ‚îÄ interaction_stats_enriched.csv    # 426 MB
‚îî‚îÄ‚îÄ preprocessing_stats.json          # < 1 KB

Total: ~560 MB
```

### Fichiers Lite (d√©ploiement)

```
/home/ser/Bureau/P10_reco/models_lite/
‚îú‚îÄ‚îÄ user_item_matrix_weighted.npz     # ~2 MB
‚îú‚îÄ‚îÄ mappings.pkl                      # ~300 KB
‚îú‚îÄ‚îÄ article_popularity.pkl            # ~150 KB
‚îú‚îÄ‚îÄ user_profiles_enriched.pkl        # ~5 MB
‚îú‚îÄ‚îÄ embeddings_filtered.pkl           # ~4 MB
‚îî‚îÄ‚îÄ articles_metadata.csv             # ~1 MB

Total: ~86 MB (r√©duction de 96%)
```

### Logs et rapports

```
/home/ser/Bureau/P10_reco_new/logs/
‚îî‚îÄ‚îÄ pipeline_20251231_143022.log      # Logs complets

/home/ser/Bureau/P10_reco_new/
‚îî‚îÄ‚îÄ PIPELINE_REPORT_20251231_143022.md  # Rapport d'ex√©cution
```

## V√©rification des r√©sultats

### Test rapide des mod√®les

```python
import pickle
from pathlib import Path
from scipy.sparse import load_npz

models_dir = Path("/home/ser/Bureau/P10_reco/models")

# Charger matrice
matrix = load_npz(models_dir / "user_item_matrix_weighted.npz")
print(f"Matrice: {matrix.shape} - {matrix.nnz:,} interactions")

# Charger profils
with open(models_dir / "user_profiles_enriched.pkl", 'rb') as f:
    profiles = pickle.load(f)
print(f"Profils: {len(profiles):,} utilisateurs")

# Test sur un utilisateur
user = profiles[58]
print(f"\nUser 58:")
print(f"  - Articles lus: {user['num_articles']}")
print(f"  - Score moyen: {user['avg_weight']:.3f}")
```

### Test de l'API localement

```bash
cd app/
streamlit run streamlit_api_v2.py
# ‚Üí http://localhost:8501
```

## R√©solution de probl√®mes

### Erreur: M√©moire insuffisante

**Sympt√¥me:** `MemoryError` ou `Killed`

**Solutions:**
1. Fermer les applications inutiles
2. Utiliser la version optimis√©e: `compute_weights_memory_optimized.py` (d√©j√† utilis√©e)
3. Augmenter le swap: `sudo swapon -s`

### Erreur: Dataset introuvable

**Sympt√¥me:** `Dataset introuvable: /home/ser/Bureau/P10_reco/news-portal-user-interactions-by-globocom`

**Solution:**
```bash
# V√©rifier le chemin
ls /home/ser/Bureau/P10_reco/news-portal-user-interactions-by-globocom

# Si n√©cessaire, modifier dans le script:
# Ligne 12: DATA_DIR="/chemin/vers/dataset"
```

### Erreur: D√©pendances manquantes

**Sympt√¥me:** `ModuleNotFoundError: No module named 'pandas'`

**Solution:**
```bash
pip install pandas numpy scipy scikit-learn
```

### Fichiers d√©j√† existants

Le script demande confirmation avant d'√©craser les fichiers existants (√©tape 3).

**Options:**
- `o` (oui) : Recalculer
- `n` (non) : Conserver l'existant et continuer

## Comparaison Kaggle vs Local

| Aspect | Kaggle | Local |
|--------|--------|-------|
| **Temps max** | 6h | Illimit√© |
| **RAM** | 16 GB | Variable |
| **GPU** | Disponible | Non (pas n√©cessaire) |
| **Stockage** | 20 GB temporaire | Permanent |
| **Debugging** | Limit√© | Total |
| **D√©mo live** | ‚ùå | ‚úÖ |
| **Co√ªt** | Gratuit | Gratuit |
| **Contr√¥le** | Moyen | Total |

## Pour la pr√©sentation

### Pr√©paration

1. **Ex√©cuter le pipeline complet** (une fois)
   ```bash
   ./run_pipeline_complet.sh
   ```

2. **V√©rifier les mod√®les**
   ```bash
   cat PIPELINE_REPORT_*.md
   ```

3. **Tester l'API Streamlit**
   ```bash
   cd app/
   ./lancer_app.sh
   ```

### D√©monstration

**Option 1: Montrer les logs**
```bash
# Afficher le dernier rapport
cat PIPELINE_REPORT_*.md | less
```

**Option 2: Ex√©cution partielle**
```bash
# Montrer juste l'√©tape de preprocessing (rapide)
python3 data_preparation/data_preprocessing_optimized.py
```

**Option 3: Application Streamlit**
- Lancer l'app
- G√©n√©rer des recommandations en direct
- Montrer l'interpr√©tabilit√© (cat√©gories, profils, etc.)

## Avantages pour les livrables

‚úÖ **Script reproductible** - Un seul fichier √† ex√©cuter
‚úÖ **Logs d√©taill√©s** - Tra√ßabilit√© compl√®te
‚úÖ **Rapport automatique** - Statistiques + fichiers g√©n√©r√©s
‚úÖ **Validation incluse** - Tests de chargement
‚úÖ **Modulaire** - Peut relancer une seule √©tape
‚úÖ **Documentation** - Commentaires + banni√®res claires

## Prochaines √©tapes

Apr√®s ex√©cution du pipeline:

1. ‚úÖ Mod√®les g√©n√©r√©s et valid√©s
2. üì§ Upload sur Azure/AWS (optionnel)
3. üß™ √âvaluation (benchmark 500 users)
4. üìä Application Streamlit pr√™te
5. üéì Pr√©sentation devant le jury

---

**Cr√©√© le:** 31 D√©cembre 2025
**Version:** 1.0
**Statut:** ‚úÖ Pr√™t pour ex√©cution
